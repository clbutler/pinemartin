Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Conda environments: ignored
Job stats:
job                               count
------------------------------  -------
clean_pine_martin_sightings           1
download_pine_martin_sightings        1
total                                 2

Select jobs to execute...
Execute 1 jobs...

[Fri Sep  6 00:02:24 2024]
localrule download_pine_martin_sightings:
    output: outputs/pine_martins_sightings.csv
    jobid: 1
    reason: Code has changed since last execution
    resources: tmpdir=/var/folders/1z/9q2sbs594sj783bxhkj9gfl80000gn/T

[Fri Sep  6 00:06:38 2024]
Finished job 1.
1 of 2 steps (50%) done
Select jobs to execute...
Execute 1 jobs...

[Fri Sep  6 00:06:38 2024]
localrule clean_pine_martin_sightings:
    input: outputs/pine_martins_sightings.csv
    output: outputs/pine_martins_sightings_clean.csv, outputs/pine_martins_sightings_plot.pdf
    jobid: 0
    reason: Input files updated by another job: outputs/pine_martins_sightings.csv
    resources: tmpdir=/var/folders/1z/9q2sbs594sj783bxhkj9gfl80000gn/T

[Sun Sep  8 13:07:32 2024]
Finished job 0.
2 of 2 steps (100%) done
Complete log: .snakemake/log/2024-09-06T000224.526488.snakemake.log
